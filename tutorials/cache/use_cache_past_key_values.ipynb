{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015aa12d-148d-4bd8-851c-f877eadc1cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:48.665730Z",
     "iopub.status.busy": "2024-11-17T09:03:48.664799Z",
     "iopub.status.idle": "2024-11-17T09:03:48.680554Z",
     "shell.execute_reply": "2024-11-17T09:03:48.679281Z",
     "shell.execute_reply.started": "2024-11-17T09:03:48.665683Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11821f25-9fa8-4b8a-80a8-35c11135f4c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:48.682930Z",
     "iopub.status.busy": "2024-11-17T09:03:48.682281Z",
     "iopub.status.idle": "2024-11-17T09:03:52.999739Z",
     "shell.execute_reply": "2024-11-17T09:03:52.998715Z",
     "shell.execute_reply.started": "2024-11-17T09:03:48.682889Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# 加载预训练模型和分词器\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f8fa25d-b619-41f9-9a09-b93e7967350a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:53.000890Z",
     "iopub.status.busy": "2024-11-17T09:03:53.000612Z",
     "iopub.status.idle": "2024-11-17T09:03:53.009618Z",
     "shell.execute_reply": "2024-11-17T09:03:53.008781Z",
     "shell.execute_reply.started": "2024-11-17T09:03:53.000874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[15496,    11,   616,  1438,   318]]), torch.Size([1, 5]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 编码初始输入\n",
    "input_ids = tokenizer.encode(\"Hello, my name is\", return_tensors='pt')\n",
    "\n",
    "# batch_size, seq_len\n",
    "input_ids, input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8fa48-ebcd-4ee3-869a-27ad9ba34f89",
   "metadata": {},
   "source": [
    "#### 第一步生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c01e80b-c4ff-4d33-b4fb-45269d204684",
   "metadata": {},
   "source": [
    "\n",
    "$$2\\times \\text{batch\\_size}\\times \\text{seq\\_len}\\times n_{\\text{layers}}\\times d_{model}\\times precison$$\n",
    "\n",
    "```\n",
    "past_key_values = (\n",
    "    (key_layer_1, value_layer_1),\n",
    "    (key_layer_2, value_layer_2),\n",
    "    ...\n",
    "    (key_layer_N, value_layer_N)\n",
    ")\n",
    "```\n",
    "\n",
    "- `{key/value}_layer_i` shape\n",
    "    - (batch_size, num_heads, seq_length, head_dim)\n",
    "- d_model = num_heads * head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f47013-58fb-485b-adfe-2b11950d7fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:53.010304Z",
     "iopub.status.busy": "2024-11-17T09:03:53.010154Z",
     "iopub.status.idle": "2024-11-17T09:03:53.111564Z",
     "shell.execute_reply": "2024-11-17T09:03:53.110629Z",
     "shell.execute_reply.started": "2024-11-17T09:03:53.010292Z"
    }
   },
   "outputs": [],
   "source": [
    "# 第一步生成\n",
    "output = model(input_ids, use_cache=True)\n",
    "next_token_logits = output.logits[:, -1, :]  # 获取最后一个时间步的 logits\n",
    "past_key_values = output.past_key_values    # 缓存键和值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ff70a3-15d9-4f4a-b362-111b4bab5bb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:53.112725Z",
     "iopub.status.busy": "2024-11-17T09:03:53.112527Z",
     "iopub.status.idle": "2024-11-17T09:03:53.118331Z",
     "shell.execute_reply": "2024-11-17T09:03:53.117559Z",
     "shell.execute_reply.started": "2024-11-17T09:03:53.112711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 50257])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7acb88b3-7c17-4add-9665-c064d25cf162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:53.120210Z",
     "iopub.status.busy": "2024-11-17T09:03:53.120063Z",
     "iopub.status.idle": "2024-11-17T09:03:53.128849Z",
     "shell.execute_reply": "2024-11-17T09:03:53.127978Z",
     "shell.execute_reply.started": "2024-11-17T09:03:53.120198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, torch.Size([1, 12, 5, 64]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(past_key_values), past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c53bc5c7-cd2d-45de-b6da-6ea034c3f59a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:40:51.820459Z",
     "iopub.status.busy": "2024-11-17T09:40:51.820061Z",
     "iopub.status.idle": "2024-11-17T09:40:51.832071Z",
     "shell.execute_reply": "2024-11-17T09:40:51.829902Z",
     "shell.execute_reply.started": "2024-11-17T09:40:51.820432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.45.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"vocab_size\": 50257\n",
    "# \"n_layer\": 12,\n",
    "# \"n_head\": 12,\n",
    "# \"n_embd\": 768,\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357237fa-bc73-485c-8d8e-8941c7bd2cc2",
   "metadata": {},
   "source": [
    "#### 采样下一个 token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc263b26-532f-42d3-8e85-3f64ec66aa98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:53.141205Z",
     "iopub.status.busy": "2024-11-17T09:03:53.141019Z",
     "iopub.status.idle": "2024-11-17T09:03:53.155231Z",
     "shell.execute_reply": "2024-11-17T09:03:53.154015Z",
     "shell.execute_reply.started": "2024-11-17T09:03:53.141190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 5, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_past_key_values = output.past_key_values\n",
    "raw_past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2bf26ee-e15f-4a04-8e47-878b8f09571d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:53.156438Z",
     "iopub.status.busy": "2024-11-17T09:03:53.156206Z",
     "iopub.status.idle": "2024-11-17T09:03:53.182510Z",
     "shell.execute_reply": "2024-11-17T09:03:53.181496Z",
     "shell.execute_reply.started": "2024-11-17T09:03:53.156420Z"
    }
   },
   "outputs": [],
   "source": [
    "# 采样下一个令牌（例如取最大概率的令牌）\n",
    "next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(-1)\n",
    "\n",
    "# 第二步生成，使用缓存\n",
    "output = model(next_token, past_key_values=past_key_values, use_cache=True)\n",
    "next_token_logits = output.logits[:, -1, :]\n",
    "past_key_values = output.past_key_values\n",
    "\n",
    "# 重复上述步骤，直到生成结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd6e25f8-f166-42cf-8acf-7546995ce293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:53.183728Z",
     "iopub.status.busy": "2024-11-17T09:03:53.183493Z",
     "iopub.status.idle": "2024-11-17T09:03:53.190891Z",
     "shell.execute_reply": "2024-11-17T09:03:53.189452Z",
     "shell.execute_reply.started": "2024-11-17T09:03:53.183709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 6, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0823e9df-aba6-4078-b4ab-703cc3cd1ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:53.191965Z",
     "iopub.status.busy": "2024-11-17T09:03:53.191746Z",
     "iopub.status.idle": "2024-11-17T09:03:53.201500Z",
     "shell.execute_reply": "2024-11-17T09:03:53.200521Z",
     "shell.execute_reply.started": "2024-11-17T09:03:53.191947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 12, 5, 64]), torch.Size([1, 12, 6, 64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_past_key_values[0][0].shape, past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b873838-9a4a-439b-9375-b4c8ee1afdb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:53.202450Z",
     "iopub.status.busy": "2024-11-17T09:03:53.202211Z",
     "iopub.status.idle": "2024-11-17T09:03:53.213869Z",
     "shell.execute_reply": "2024-11-17T09:03:53.212078Z",
     "shell.execute_reply.started": "2024-11-17T09:03:53.202431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(past_key_values[0][0][:, :, :5, :], raw_past_key_values[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be4236-9b11-4a85-a1a0-56770200be93",
   "metadata": {},
   "source": [
    "### 对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f1f823-cddc-4fae-b1be-747ef3344b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:53.215105Z",
     "iopub.status.busy": "2024-11-17T09:03:53.214852Z",
     "iopub.status.idle": "2024-11-17T09:03:55.102605Z",
     "shell.execute_reply": "2024-11-17T09:03:55.101638Z",
     "shell.execute_reply.started": "2024-11-17T09:03:53.215085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'gpt2'  \n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6b4813a-20cf-46ab-a511-0874f6b1358e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:55.103772Z",
     "iopub.status.busy": "2024-11-17T09:03:55.103556Z",
     "iopub.status.idle": "2024-11-17T09:03:55.109646Z",
     "shell.execute_reply": "2024-11-17T09:03:55.108654Z",
     "shell.execute_reply.started": "2024-11-17T09:03:55.103755Z"
    }
   },
   "outputs": [],
   "source": [
    "input_text = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)  # 形状: (1, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43de0bb8-a395-40f0-bdbc-d31fc6eab2bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:55.110434Z",
     "iopub.status.busy": "2024-11-17T09:03:55.110242Z",
     "iopub.status.idle": "2024-11-17T09:03:55.128601Z",
     "shell.execute_reply": "2024-11-17T09:03:55.127601Z",
     "shell.execute_reply.started": "2024-11-17T09:03:55.110418Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 30  # 生成的最大长度，包括输入长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84ab342d-63d5-420c-8dc5-e767b625973c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:03:55.129681Z",
     "iopub.status.busy": "2024-11-17T09:03:55.129437Z",
     "iopub.status.idle": "2024-11-17T09:03:55.138197Z",
     "shell.execute_reply": "2024-11-17T09:03:55.137137Z",
     "shell.execute_reply.started": "2024-11-17T09:03:55.129661Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77968616-f651-4019-84cd-5ba6ba45a943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:07:43.144114Z",
     "iopub.status.busy": "2024-11-17T09:07:43.143804Z",
     "iopub.status.idle": "2024-11-17T09:07:43.398388Z",
     "shell.execute_reply": "2024-11-17T09:07:43.396586Z",
     "shell.execute_reply.started": "2024-11-17T09:07:43.144094Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 使用 model.generate（贪婪搜索）生成的文本 ===\n",
      "Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was\n"
     ]
    }
   ],
   "source": [
    "# 使用 model.generate 生成文本（贪婪搜索）\n",
    "greedy_output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=max_length,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=False  # 关闭采样，使用贪婪搜索\n",
    ")\n",
    "greedy_text = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "print(\"\\n=== 使用 model.generate（贪婪搜索）生成的文本 ===\")\n",
    "print(greedy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edffbc14-0f8b-4dff-83d9-bc337c137f14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:07:46.351575Z",
     "iopub.status.busy": "2024-11-17T09:07:46.351285Z",
     "iopub.status.idle": "2024-11-17T09:07:46.640877Z",
     "shell.execute_reply": "2024-11-17T09:07:46.639104Z",
     "shell.execute_reply.started": "2024-11-17T09:07:46.351555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 使用循环和 past_key_values（贪婪搜索）逐步生成的文本 ===\n",
      "Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was\n"
     ]
    }
   ],
   "source": [
    "# 手动逐步生成文本（贪婪搜索）\n",
    "generated_tokens = input_ids\n",
    "past_key_values = None\n",
    "\n",
    "steps = max_length - input_ids.shape[1]\n",
    "\n",
    "for step in range(steps):\n",
    "    if step == 0:\n",
    "        # 第一轮，传递整个输入\n",
    "        outputs = model(generated_tokens, use_cache=True)\n",
    "    else:\n",
    "        # 后续轮次，只传递最后一个 token\n",
    "        outputs = model(next_token, use_cache=True, past_key_values=past_key_values)\n",
    "    \n",
    "    # 更新 past_key_values\n",
    "    past_key_values = outputs.past_key_values\n",
    "    \n",
    "    # 获取 logits 并选择下一个 token\n",
    "    next_token_logits = outputs.logits[:, -1, :]  # 取最后一个时间步的 logits\n",
    "    \n",
    "    # 选择概率最高的 token（贪婪搜索）\n",
    "    next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(-1)  # 形状: (batch_size, 1)\n",
    "    \n",
    "    # 将新生成的 token 添加到生成的序列中\n",
    "    generated_tokens = torch.cat((generated_tokens, next_token), dim=1)\n",
    "\n",
    "\n",
    "# 解码生成的文本\n",
    "greedy_loop_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "print(\"\\n=== 使用循环和 past_key_values（贪婪搜索）逐步生成的文本 ===\")\n",
    "print(greedy_loop_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a3abd7-fe90-496e-bbed-8b5c3bcff122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
