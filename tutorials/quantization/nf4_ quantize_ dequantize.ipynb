{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885760f6-62df-4bdb-9f2f-a8517df142a3",
   "metadata": {},
   "source": [
    "https://id2thomas.medium.com/ml-bitsandbytes-nf4-quantize-dequantize-analysis-1ad91d9912c9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c558736-daef-4fcb-a747-e44280b66a76",
   "metadata": {},
   "source": [
    "- Normalization: The weights of the model are normalized so that we expect the weights to fall within a certain range. This allows for more efficient representation of more common values.\n",
    "\n",
    "- Quantization: The weights are quantized to 4-bit. In NF4, the quantization levels are evenly spaced with respect to the normalized weights, thereby efficiently representing the original 32-bit weights.\n",
    "\n",
    "- Dequantization: Although the weights are stored in 4-bit, they are dequantized during **computation** which gives a performance boost during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc70ca03-5c0f-4b5a-9a4d-38a1afbf0468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T04:59:36.111818Z",
     "iopub.status.busy": "2024-07-21T04:59:36.111408Z",
     "iopub.status.idle": "2024-07-21T04:59:36.119660Z",
     "shell.execute_reply": "2024-07-21T04:59:36.117984Z",
     "shell.execute_reply.started": "2024-07-21T04:59:36.111796Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63dab861-20bc-4f29-b86c-9a7782de74af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T04:58:55.084453Z",
     "iopub.status.busy": "2024-07-21T04:58:55.083834Z",
     "iopub.status.idle": "2024-07-21T04:58:56.720978Z",
     "shell.execute_reply": "2024-07-21T04:58:56.720177Z",
     "shell.execute_reply.started": "2024-07-21T04:58:55.084406Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "\t\tload_in_4bit=True,\n",
    "\t\tbnb_4bit_use_double_quant=False,\n",
    "\t\tbnb_4bit_quant_type=\"nf4\",\n",
    "\t\tbnb_4bit_compute_dtype=torch.bfloat16\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccdbe5a-70d1-4584-a8f8-06d58e06ca0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T04:59:37.902013Z",
     "iopub.status.busy": "2024-07-21T04:59:37.901350Z",
     "iopub.status.idle": "2024-07-21T04:59:52.206221Z",
     "shell.execute_reply": "2024-07-21T04:59:52.205373Z",
     "shell.execute_reply.started": "2024-07-21T04:59:37.901965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58ff28508834b7a8794943e68b497e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    }
   ],
   "source": [
    "gpu_num = 0\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "\t\"meta-llama/Meta-Llama-3-8B-Instruct\", \n",
    "\tdevice_map = {\"\": \"cuda:\" + str(gpu_num)},\n",
    "\tquantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d1bc95-6806-48b4-8343-91d056d318c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T05:00:09.224552Z",
     "iopub.status.busy": "2024-07-21T05:00:09.224094Z",
     "iopub.status.idle": "2024-07-21T05:00:09.236890Z",
     "shell.execute_reply": "2024-07-21T05:00:09.235006Z",
     "shell.execute_reply.started": "2024-07-21T05:00:09.224529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a8af82-576b-4a9c-ae37-a248ec8e0d65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T05:02:19.528493Z",
     "iopub.status.busy": "2024-07-21T05:02:19.527888Z",
     "iopub.status.idle": "2024-07-21T05:02:19.556192Z",
     "shell.execute_reply": "2024-07-21T05:02:19.554197Z",
     "shell.execute_reply.started": "2024-07-21T05:02:19.528448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "Parameter(Params4bit([[ 97],\n",
       "            [101],\n",
       "            [110],\n",
       "            ...,\n",
       "            [119],\n",
       "            [ 88],\n",
       "            [119]], device='cuda:0', dtype=torch.uint8))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = model.model.layers[0].self_attn.q_proj.weight\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a48dac-0d9f-43bd-a75b-181fa5b8ce89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T05:02:28.293248Z",
     "iopub.status.busy": "2024-07-21T05:02:28.292639Z",
     "iopub.status.idle": "2024-07-21T05:02:28.303892Z",
     "shell.execute_reply": "2024-07-21T05:02:28.301860Z",
     "shell.execute_reply.started": "2024-07-21T05:02:28.293205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.uint8, torch.Size([8388608, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.dtype, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50165980-fe15-44b7-adbf-3841b00352ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T05:01:57.350090Z",
     "iopub.status.busy": "2024-07-21T05:01:57.349644Z",
     "iopub.status.idle": "2024-07-21T05:01:57.363243Z",
     "shell.execute_reply": "2024-07-21T05:01:57.361164Z",
     "shell.execute_reply.started": "2024-07-21T05:01:57.350060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, device='cuda:0', dtype=torch.uint8),\n",
       " tensor(255, device='cuda:0', dtype=torch.uint8))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(W), torch.max(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe77fbf5-9fe4-4ffc-b6da-6b72b9c89e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T05:04:02.605809Z",
     "iopub.status.busy": "2024-07-21T05:04:02.605121Z",
     "iopub.status.idle": "2024-07-21T05:04:02.623414Z",
     "shell.execute_reply": "2024-07-21T05:04:02.621226Z",
     "shell.execute_reply.started": "2024-07-21T05:04:02.605762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 101]\n",
      "01100001\n",
      "01100101\n"
     ]
    }
   ],
   "source": [
    "print([v[0] for v in W[:2].cpu().numpy().tolist()])\n",
    "# [97, 101]\n",
    "print(format(W[0].item(), '08b'))\n",
    "# 01100001\n",
    "print(format(W[1].item(), '08b'))\n",
    "# 01100101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbbefe1c-be87-4041-b81d-58ad93a411f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T05:04:49.499835Z",
     "iopub.status.busy": "2024-07-21T05:04:49.499191Z",
     "iopub.status.idle": "2024-07-21T05:04:49.509069Z",
     "shell.execute_reply": "2024-07-21T05:04:49.507073Z",
     "shell.execute_reply.started": "2024-07-21T05:04:49.499788Z"
    }
   },
   "outputs": [],
   "source": [
    "absmax, shape, dtype, blocksize, compressed_stats, quant_type, data_type = W.quant_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99164fe5-f369-4cec-b7ee-a3da464ada34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T05:05:42.300045Z",
     "iopub.status.busy": "2024-07-21T05:05:42.299395Z",
     "iopub.status.idle": "2024-07-21T05:05:42.321020Z",
     "shell.execute_reply": "2024-07-21T05:05:42.319047Z",
     "shell.execute_reply.started": "2024-07-21T05:05:42.300000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absmax tensor([0.0405, 0.0386, 0.0376,  ..., 0.0581, 0.0957, 0.1079], device='cuda:0') torch.Size([262144])\n",
      "shape torch.Size([4096, 4096])\n",
      "dtype torch.float16\n",
      "blocksize 64\n",
      "quant_type nf4\n",
      "data_type tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
      "         0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
      "       device='cuda:0') 16\n"
     ]
    }
   ],
   "source": [
    "print(\"absmax\", absmax, absmax.shape)\n",
    "\n",
    "print(\"shape\", shape) # (4096,4096) -> original shape\n",
    "print(\"dtype\", dtype) # dtype torch.float16\n",
    "print(\"blocksize\", blocksize) # 64\n",
    "print(\"quant_type\", quant_type) # quant_type nf4\n",
    "print(\"data_type\", data_type, len(data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f4e7c1b-cbd1-46d1-982d-c9fe63fbfb41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T05:06:51.345262Z",
     "iopub.status.busy": "2024-07-21T05:06:51.344614Z",
     "iopub.status.idle": "2024-07-21T05:06:51.359788Z",
     "shell.execute_reply": "2024-07-21T05:06:51.358011Z",
     "shell.execute_reply.started": "2024-07-21T05:06:51.345214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 4096])\n",
      "tensor([-0.0037, -0.0282, -0.0037,  ...,  0.0078, -0.0483, -0.0190],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes.functional as F\n",
    "dequantized = F.dequantize_4bit(W, W.quant_state).to(torch.bfloat16)\n",
    "print(dequantized.shape) # (4096, 4096) - (3*hidden_size, hidden_size)\n",
    "print(dequantized[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e0dc907-6e7f-4408-af31-3f52469e9e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T05:07:30.694419Z",
     "iopub.status.busy": "2024-07-21T05:07:30.693764Z",
     "iopub.status.idle": "2024-07-21T05:07:30.718594Z",
     "shell.execute_reply": "2024-07-21T05:07:30.715890Z",
     "shell.execute_reply.started": "2024-07-21T05:07:30.694373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absmax of block: tensor(0.0405, dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "def get_absmax(x):\n",
    "\treturn max(abs(x))\n",
    "\n",
    "weight_block = dequantized[0][:blocksize].clone().cpu()\n",
    "absmax = get_absmax(weight_block)\n",
    "print(\"absmax of block:\", absmax)\n",
    "# absmax of block: tensor(0.0491, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274d9d5-9eac-4f53-b28d-0b0b51314258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
